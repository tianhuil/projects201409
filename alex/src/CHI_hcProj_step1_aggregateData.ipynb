{
 "metadata": {
  "name": "",
  "signature": "sha256:01dbe9c7716dcc219bfb6546ed7bf25dd5c98477773bd4916c7a7204c123e5d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "import matplotlib as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Notes\n",
      "1. Data sources and CSV information stored in corresponding evernote file... need to create a Makefile on the weekend. </li>\n",
      "1. Zillow only contains housing data for 72 of the 77 communities\n",
      "1. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reads Housing Data\n",
      "city = 'Chicago'\n",
      "cty2BmedSale = pd.read_csv('../data/City_Zhvi_2bedroom.csv')\n",
      "neib2BmedSale = pd.read_csv('../data/Neighborhood_Zhvi_2bedroom.csv')\n",
      "\n",
      "cty2BmedSale = cty2BmedSale[cty2BmedSale.RegionName == city]\n",
      "\n",
      "s2Bcity = cty2BmedSale.ix[:,'1996-04':'2014-07'].T\n",
      "s2Bcity.columns = ['salePrice']\n",
      "\n",
      "# Prices df for 2B houses by <city> neighbourhood\n",
      "neib2BmedSale = neib2BmedSale[neib2BmedSale.City == city] # THERE ARE ONLY 72 COMMUNITIES here :O, instead of 77\n",
      "df_prices = neib2BmedSale.set_index('RegionName')\n",
      "df_prices = df_prices.drop(['Metro','City','State','CountyName'],axis=1)\n",
      "df_prices = df_prices.T # Transposes\n",
      "df_prices.index = pd.to_datetime(df_prices.index) # Changes indexes to a datetime object\n",
      "\n",
      "df_prices['CityMed'] = s2Bcity.salePrice # adds city wide med saleprice\n",
      "df_prices['Year'] = [df_prices.index[k].year for k in range(len(df_prices))] # can be more efficient\n",
      "#df_prices['Month'] = [df_prices.index[k].month for k in range(len(df_prices))]\n",
      "\n",
      "# Chi price index (wrt city-wide median price)\n",
      "df_priceIdxs = df_prices.div(df_prices.CityMed, axis='index')\n",
      "\n",
      "# Calculating Price by Yr\n",
      "df_pricesByYr = df_prices.groupby('Year').mean() # also drop Month if this column has been made\n",
      "df_pricesByYr = df_pricesByYr.drop(['CityMed'],1).T # cleaning\n",
      "df_pricesByYr = df_pricesByYr.drop(range(1996,2010),1)\n",
      "df_pricesByYr = df_pricesByYr.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# This tests out a plot and checks that the datetimes work \n",
      "neib2BpriceIdx['Rogers Park'].plot(style='k.-', legend = False, ylim = [0.4,0.85]) "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read Other Data\n",
      "df_neibScores = pd.read_csv('../data/walkscores.csv') # second merge to df_join2\n",
      "df_neibCom = pd.read_csv('../data/neibCom.csv') # second merge to df_join2\n",
      "df_comNumsArea = pd.read_csv('../data/CHIcommAreaNums.csv') # first merge to df_join1\n",
      "df_comAreas = pd.read_csv('../data/CommAreas.csv') # first merge to df_join1\n",
      "df_popInc2010 = pd.read_csv('../data/CHIcomPopIncome.csv') # 2010 data\n",
      "\n",
      "# Reorganizing data frames:\n",
      "# Convert neibPop data from string numbers with commas to floats\n",
      "df_neibScores['neibPop'] = df_neibScores.neibPop.apply(lambda x: float(''.join(x.split(','))))\n",
      "\n",
      "df_comAreas.rename(columns={'COMMUNITY':'comNameLong', 'AREA_NUMBE':'comNum'}, inplace=True) # renames on column for joining\n",
      "df_comAreas['comNameLong'] = df_comAreas.comNameLong.str.lower().str.title() # Converts string format in community\n",
      "\n",
      "df_popInc2010 = df_popInc2010[:3].ix[:, 1:].T\n",
      "df_popInc2010.columns = ['comName_cen2010','comPop2010','medInc2010']\n",
      "df_popInc2010['comNum'] = np.arange(1,78)\n",
      "df_popInc2010.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>comName_cen2010</th>\n",
        "      <th>comPop2010</th>\n",
        "      <th>medInc2010</th>\n",
        "      <th>comNum</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Rogers Park</td>\n",
        "      <td> 54991</td>\n",
        "      <td> 39482</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>     West Ridge</td>\n",
        "      <td> 71942</td>\n",
        "      <td> 47323</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>         Uptown</td>\n",
        "      <td> 56362</td>\n",
        "      <td> 40324</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Lincoln Square</td>\n",
        "      <td> 39493</td>\n",
        "      <td> 57749</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>   North Center</td>\n",
        "      <td> 31867</td>\n",
        "      <td> 81524</td>\n",
        "      <td> 5</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "  comName_cen2010 comPop2010 medInc2010  comNum\n",
        "1     Rogers Park      54991      39482       1\n",
        "2      West Ridge      71942      47323       2\n",
        "3          Uptown      56362      40324       3\n",
        "4  Lincoln Square      39493      57749       4\n",
        "5    North Center      31867      81524       5"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# *** JOIN 1\n",
      "df_join1 = df_comAreas.merge(df_comNumsArea, on='comNum')\n",
      "\n",
      "# clean up and sort df_join1\n",
      "df_join1.drop(['PERIMETER','AREA','COMAREA_','COMAREA_ID','AREA_NUM_1','SHAPE_AREA','SHAPE_LEN'], axis=1, inplace=True)\n",
      "df_join1 = df_join1.sort_index(by='comNum', ascending=True)\n",
      "## Have checked, no loss of data in the join1 merge\n",
      "\n",
      "# *** JOIN 2\n",
      "df_join2 = df_neibScores.merge(df_neibCom, on='neib') # df_neibCom is a dictionary from neibs to communties\n",
      "df_join2.rename(columns={'comm':'comNameLong'}, inplace =True)\n",
      "\n",
      "df_join2Out = df_neibScores.merge(df_neibCom, how='outer', on='neib') # df_neibCom is a dictionary from neibs to communties\n",
      "df_neibsToAddMan = df_join2Out[pd.isnull(df_join2Out.comm)]\n",
      "df_neibsToAddMan.to_csv('../data/addToDict.csv')\n",
      "\n",
      "df_neibCom2 = pd.read_csv('../data/neibCom2.csv') # Now I've manually apennded the dictionary for the remaining names \n",
      "df_join2_fixed = df_neibScores.merge(df_neibCom2, on='neib')\n",
      "df_join2_fixed.rename(columns={'comm':'comNameLong'}, inplace =True)\n",
      "\n",
      "# Calculating mean walkscore.com scores\n",
      "df_join2comSc = df_join2_fixed.groupby('comNameLong')['walkScore','tranScore','bikeScore'].mean().reset_index()\n",
      "df_join2pop = df_join2_fixed.groupby('comNameLong')['neibPop'].sum().reset_index()\n",
      "df_join2pop.rename(columns={'neibPop':'comPop'}, inplace=True)\n",
      "# I've checked that the above give the correct amount of communities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The following determines the number of neighbourhoods within each community\n",
      "#df_neibCom.groupby('comm').apply(lambda x: len(x)) # Anything more than 77 is a problem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The following shows what communities should be cleaned, if any... no big deal to leave them as they'll be removed in any inner merge\n",
      "extraCom = df_join2pop.merge(df_join1, how='outer', on='comNameLong')\n",
      "extraCom[extraCom.comNum.isnull() | extraCom.comPop.isnull() ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>comNameLong</th>\n",
        "      <th>comPop</th>\n",
        "      <th>comNum</th>\n",
        "      <th>comName</th>\n",
        "      <th>area</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> Chatham,?Roseland</td>\n",
        "      <td> 4136</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "          comNameLong  comPop  comNum comName  area\n",
        "15  Chatham,?Roseland    4136     NaN     NaN   NaN"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_main = df_popInc2010.merge(df_join2comSc.merge(df_join2pop.merge(df_join1, on='comNameLong'), on='comNameLong'), on='comNum')\n",
      "len(unique(df_main.comNum)) #  Checks that all the communities are accounted for :-)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'df_popInc2010' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-82854784e38a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_popInc2010\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_join2comSc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_join2pop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_join1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'comNameLong'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'comNameLong'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'comNum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_main\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#  Checks that all the communities are accounted for :-)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'df_popInc2010' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unfortunately, I realized late in the game Zillow didn't have all the community data\n",
      "#... n=39 instead of 77 >*_*>\n",
      "\n",
      "df_pricesByYr.rename(columns={'RegionName':'neib'},inplace=True)\n",
      "df_neibCom_zillowData = pd.read_csv('../data/neibCom_zillowData.csv')\n",
      "df_pricesByYrComm = df_pricesByYr.merge(df_neibCom_zillowData, on='neib', how='inner').groupby('comNameLong').mean()\n",
      "df_pricesByYrComm = df_pricesByYrComm.reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# creating df_main2, which is a merge left so I can keep all the community data, even if I don't have pricing data for that community\n",
      "\n",
      "df_main2 = df_main.merge(df_pricesByYrComm, on='comNameLong', how='left')\n",
      "\n",
      "# The following is a really ugly quick loop to convert non string column headers to formatted strings\n",
      "tempColList = list(df_main2.columns)\n",
      "for idx in range(len(tempColList)):\n",
      "    if type(tempColList[idx]) == type(1):\n",
      "        tempColList[idx] = 'Pr'+str(tempColList[idx])\n",
      "df_main2.columns = tempColList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read City of Chicago Crime Data\n",
      "\n",
      "df_crimeDataR = pd.read_csv('../data/Crimes_-_2001_to_present.csv', iterator=True, chunksize=1000, nrows=10000000, usecols = [2,3]+range(5,15)+[17,19,20])\n",
      "df_crimeDataR.rename(columns = {'Community Area':'comNum'}, inplace=True)\n",
      "\n",
      "# The following converts all the comNums into the same format:\n",
      "def convert_to_float(x):\n",
      "    if type(x)==type('hello'): # type string\n",
      "        if x.isdigit()==True:\n",
      "            return float(x)\n",
      "        else:\n",
      "            return 0.\n",
      "    elif type(x)==type(1): # type integer\n",
      "        return float(x)\n",
      "    elif type(x)==type(1.): # type float\n",
      "        if np.isnan(x):\n",
      "            return 0.\n",
      "        else:\n",
      "            return x\n",
      "    else:\n",
      "        return 0.\n",
      "\n",
      "df_crimeDataR.comNum = df_crimeDataR.comNum.apply(convert_to_float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/aloosley/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1130: DtypeWarning: Columns (11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  data = self._reader.read(nrows)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# All crimesby year:\n",
      "df_crimeByYr = pd.DataFrame(df_crimeDataR.groupby(['comNum','Year']).apply(lambda x:len(x)))\n",
      "df_crimeByYr = df_crimeByYr.unstack()\n",
      "df_crimeByYr.columns = df_crimeByYr.columns.droplevel() # This drops off the top allCrimeSum at the top\n",
      "df_crimeByYr = df_crimeByYr.drop(0).reset_index() # drops the crimes in unknown communities and resets the index in anticipation of a merge\n",
      "df_crimeByYr = df_crimeByYr.drop(range(2001,2005),1)\n",
      "df_TAall = pd.DataFrame(df_crimeByYr.ix[:,2005:2010].apply(lambda x: np.nanmean(x), axis=1), columns = ['ALL_TA2010'])\n",
      "df_TAall['comNum'] = df_crimeByYr.comNum\n",
      "\n",
      "# Seek out kind of crimes to focus on:\n",
      "df_crimeByTypeByYr = pd.DataFrame(df_crimeDataR.groupby(['comNum','Primary Type','Year']).apply(lambda x: len(x)), \n",
      "                                  columns = ['numCrimes'])\n",
      "\n",
      "\n",
      "# Calculates the 2005:2010 time averaged number of crimes per year, by homicide, battery, etc.\n",
      "def TAcrime_05to10(df, primType):\n",
      "    df_ret = df.xs(primType, level='Primary Type').unstack()\n",
      "    df_ret.columns = df_ret.columns.droplevel() # This drops off the top numCrimes at the top\n",
      "    df_ret.reset_index(level=1)\n",
      "    colNm = primType[:3]+'_TA2010'\n",
      "    return df_ret.ix[1:,2005:2010].apply(lambda x: np.nanmean(x), axis=1).reset_index(level=1).rename(columns = {0:colNm})\n",
      "\n",
      "df_TAhomi = pd.DataFrame(TAcrime_05to10(df_crimeByTypeByYr, 'HOMICIDE'))\n",
      "df_TAbatt = pd.DataFrame(TAcrime_05to10(df_crimeByTypeByYr, 'BATTERY'))\n",
      "df_TAburg = pd.DataFrame(TAcrime_05to10(df_crimeByTypeByYr, 'BURGLARY'))\n",
      "df_TArobb = pd.DataFrame(TAcrime_05to10(df_crimeByTypeByYr, 'ROBBERY'))\n",
      "df_TAnarc = pd.DataFrame(TAcrime_05to10(df_crimeByTypeByYr, 'NARCOTICS'))\n",
      "\n",
      "# Concatinates all crime data into one data frame for a final merge below:\n",
      "df_TAcrimes = pd.concat([df_TAhomi, df_TAbatt, df_TAburg, df_TArobb, df_TAnarc, df_TAall], axis=1)\n",
      "colsToKeep = df1.columns != 'comNum'\n",
      "colsToKeep[0] = True\n",
      "df_TAcrimes = df_TAcrimes.ix[:,colsToKeep]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mainFinal = df_main2.merge(df_TAcrimes, on='comNum')\n",
      "\n",
      "# Save CSV\n",
      "df_mainFinal.to_csv('../data/mergedData.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Now head over to CHI_hcProj_step2_regAnal"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}